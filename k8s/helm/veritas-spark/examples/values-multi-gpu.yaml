# Veritas SPARK Multi-GPU Values
# Configuration for multi-GPU deployment with load balancing
# Suitable for: High-throughput production inference, large models

---
# Multiple replicas for load balancing
replicaCount: 3

# Container image configuration
image:
  repository: veritas-spark/core
  pullPolicy: IfNotPresent
  tag: "0.6.5"

# GPU resource allocation per pod
resources:
  limits:
    cpu: 8
    memory: 32Gi
    nvidia.com/gpu: 2
  requests:
    cpu: 4
    memory: 16Gi
    nvidia.com/gpu: 2

# GPU configuration
gpu:
  enabled: true
  type: "nvidia"
  memoryFraction: 0.85
  # Multi-GPU settings
  multiGpu:
    enabled: true
    # Tensor parallelism for large models
    tensorParallelism: 2
    # Pipeline parallelism (1 = no pipeline parallelism)
    pipelineParallelism: 1

# Model configuration
model:
  enabled: true
  # Larger model for multi-GPU (70B parameter)
  name: "llama-2-70b-chat"
  quantization: "q4_0"
  cacheDir: "/models"
  preload: true
  contextLength: 4096
  batchSize: 64
  # Multi-GPU model settings
  tensorSplit: [1, 1] # Equal split across GPUs

# Service configuration
service:
  type: ClusterIP
  port: 8080
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    prometheus.io/path: "/metrics"
  # Session affinity for streaming connections
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600

# Ingress configuration
ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
  hosts:
    - host: inference.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: veritas-spark-tls
      hosts:
        - inference.example.com

# Security context (production)
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
      - ALL

# Pod security context
podSecurityContext:
  fsGroup: 1000
  seccompProfile:
    type: RuntimeDefault

# Node selector for multi-GPU nodes
nodeSelector:
  nvidia.com/gpu.count: "2"

# Tolerations for GPU nodes
tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"

# Anti-affinity to spread across nodes
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - veritas-spark
          topologyKey: kubernetes.io/hostname
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: nvidia.com/gpu.product
              operator: In
              values:
                - NVIDIA-A100-SXM4-80GB
                - NVIDIA-H100-SXM5

# Health checks
livenessProbe:
  enabled: true
  initialDelaySeconds: 180 # Longer for large model loading
  periodSeconds: 10
  timeoutSeconds: 10
  failureThreshold: 3

readinessProbe:
  enabled: true
  initialDelaySeconds: 120
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

# Logging configuration
logging:
  level: "info"
  format: "json"
  output: "stdout"

# Metrics enabled
metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 15s
    labels:
      release: prometheus

# Tracing configuration
tracing:
  enabled: true
  endpoint: "jaeger-collector.observability.svc.cluster.local:14268"
  sampleRate: 0.1

# Canary deployment enabled
canary:
  enabled: true
  # Canary analysis settings
  analysis:
    interval: 60s
    threshold: 3
    maxWeight: 50
    stepWeight: 10
  # Metrics thresholds
  thresholds:
    errorRate: 0.01
    p99Latency: 500ms
    throughput: 95

# Blue-green deployment (alternative to canary)
blueGreen:
  enabled: false

# Environment variables
env:
  - name: RUST_LOG
    value: "info"
  - name: VERITAS_ENV
    value: "production"
  - name: CUDA_VISIBLE_DEVICES
    value: "0,1"

# ConfigMap data
config:
  inference:
    maxTokens: 4096
    temperature: 0.7
    topP: 0.9
    repetitionPenalty: 1.1
  security:
    inputValidation: true
    outputFiltering: true
    piiDetection: true
    promptInjectionDetection: true
  performance:
    kvCacheSize: 2000
    batchSize: 64
    # Multi-GPU optimizations
    tensorParallelSize: 2
    pipelineParallelSize: 1

# Persistence for model cache
persistence:
  enabled: true
  accessMode: ReadWriteOnce
  size: 200Gi
  storageClass: "fast-ssd"
  mountPath: "/models"

# Service account
serviceAccount:
  create: true
  annotations: {}
  name: ""

# RBAC
rbac:
  create: true

# Priority class
priorityClassName: "high-priority"

# Pod disruption budget
podDisruptionBudget:
  enabled: true
  minAvailable: 2

# Horizontal pod autoscaler
autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  # Custom metrics
  metrics:
    - type: Pods
      pods:
        metric:
          name: veritas_inference_queue_depth
        target:
          type: AverageValue
          averageValue: 10

# Network policies
networkPolicy:
  enabled: true
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: istio-system
      ports:
        - protocol: TCP
          port: 8080
  egress:
    - to:
        - namespaceSelector:
            matchLabels:
              name: observability
      ports:
        - protocol: TCP
          port: 14268
    - to:
        - namespaceSelector: {}
          podSelector:
            matchLabels:
              app.kubernetes.io/name: veritas-spark
      ports:
        - protocol: TCP
          port: 8080

# Pod annotations
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8080"

# Pod labels
podLabels:
  app.kubernetes.io/component: inference
  app.kubernetes.io/part-of: veritas-spark
  veritas-spark.io/gpu-count: "2"

# Additional containers
extraContainers: []

# Additional volumes
extraVolumes:
  - name: tmp
    emptyDir: {}
  - name: dshm
    emptyDir:
      medium: Memory
      sizeLimit: 16Gi

# Additional volume mounts
extraVolumeMounts:
  - name: tmp
    mountPath: /tmp
  - name: dshm
    mountPath: /dev/shm

# Init containers
initContainers:
  - name: model-downloader
    image: busybox:1.36
    command: ["sh", "-c", 'echo "Model preloading handled by main container"']
