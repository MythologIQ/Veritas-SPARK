/*
 * Veritas SPARK - Secure Performance-Accelerated Runtime Kernel
 * C API Header
 *
 * Copyright 2024-2026 Veritas SPARK Contributors
 * SPDX-License-Identifier: Apache-2.0
 */

#ifndef VERITAS_SPARK_H
#define VERITAS_SPARK_H

#include <stdint.h>
#include <stdbool.h>
#include <stddef.h>

#ifdef __cplusplus
extern "C" {
#endif


/* Warning: This file is auto-generated by cbindgen. Do not modify manually. */

/**
 * Maximum text input size in bytes (64KB).
 */
#define MAX_TEXT_BYTES 65536

/**
 * Maximum batch size for batch operations.
 */
#define MAX_BATCH_SIZE 32

/**
 * Maximum token count per input.
 */
#define MAX_INPUT_TOKENS 4096

/**
 * Block size for quantized formats.
 */
#define QUANT_BLOCK_SIZE 32

/**
 * Tokens stored per page (vLLM standard).
 */
#define PAGE_TOKENS 16

/**
 * Maximum history entries per model (default).
 */
#define DEFAULT_MAX_HISTORY 10

/**
 * Encryption key size (256 bits)
 */
#define KEY_SIZE 32

/**
 * Nonce size (96 bits for GCM)
 */
#define NONCE_SIZE 12

/**
 * Tag size (128 bits)
 */
#define TAG_SIZE 16

/**
 * Block size
 */
#define BLOCK_SIZE 16

/**
 * Maximum message size (100MB)
 */
#define DistributedMessage_MAX_SIZE ((100 * 1024) * 1024)

/**
 * Memory alignment requirement for tensor data (bytes)
 * 64 bytes aligns with AVX-512 SIMD and most GPU cache lines
 */
#define TENSOR_ALIGNMENT 64

/**
 * Exit codes for health probes.
 */
#define EXIT_HEALTHY 0

#define EXIT_UNHEALTHY 1

/**
 * Error codes for FFI functions
 */
enum CoreErrorCode {
  CORE_ERROR_CODE_OK = 0,
  CORE_ERROR_CODE_NULL_POINTER = -1,
  CORE_ERROR_CODE_INVALID_CONFIG = -2,
  CORE_ERROR_CODE_AUTH_FAILED = -3,
  CORE_ERROR_CODE_SESSION_EXPIRED = -4,
  CORE_ERROR_CODE_SESSION_NOT_FOUND = -5,
  CORE_ERROR_CODE_RATE_LIMITED = -6,
  CORE_ERROR_CODE_MODEL_NOT_FOUND = -7,
  CORE_ERROR_CODE_MODEL_LOAD_FAILED = -8,
  CORE_ERROR_CODE_INFERENCE_FAILED = -9,
  CORE_ERROR_CODE_CONTEXT_EXCEEDED = -10,
  CORE_ERROR_CODE_INVALID_PARAMS = -11,
  CORE_ERROR_CODE_QUEUE_FULL = -12,
  CORE_ERROR_CODE_SHUTTING_DOWN = -13,
  CORE_ERROR_CODE_TIMEOUT = -14,
  CORE_ERROR_CODE_CANCELLED = -15,
  CORE_ERROR_CODE_INTERNAL = -99,
};
typedef int32_t CoreErrorCode;

/**
 * Health state enumeration
 */
typedef enum CoreHealthState {
  CORE_HEALTH_STATE_HEALTHY = 0,
  CORE_HEALTH_STATE_DEGRADED = 1,
  CORE_HEALTH_STATE_UNHEALTHY = 2,
} CoreHealthState;

/**
 * Opaque handle wrapping Rust runtime
 */
typedef struct CoreRuntime CoreRuntime;

/**
 * Session handle with reference counting
 */
typedef struct CoreSession CoreSession;

/**
 * Protocol version for negotiating encoding strategies.
 */
typedef struct ProtocolVersion ProtocolVersion;

/**
 * Health check report
 */
typedef struct CoreHealthReport {
  /**
   * Overall health state
   */
  enum CoreHealthState state;
  /**
   * Ready to accept requests
   */
  bool ready;
  /**
   * Currently accepting requests
   */
  bool accepting_requests;
  /**
   * Number of models loaded
   */
  uint32_t models_loaded;
  /**
   * Memory used in bytes
   */
  uint64_t memory_used_bytes;
  /**
   * Current queue depth
   */
  uint32_t queue_depth;
  /**
   * Uptime in seconds
   */
  uint64_t uptime_secs;
} CoreHealthReport;

/**
 * Inference parameters (matches InferenceParams)
 */
typedef struct CoreInferenceParams {
  /**
   * Maximum tokens to generate (default: 256)
   */
  uint32_t max_tokens;
  /**
   * Temperature for sampling (default: 0.7)
   */
  float temperature;
  /**
   * Top-p (nucleus) sampling (default: 0.9)
   */
  float top_p;
  /**
   * Top-k sampling (default: 40)
   */
  uint32_t top_k;
  /**
   * Enable streaming output (default: false)
   */
  bool stream;
  /**
   * Timeout in milliseconds (0 = no timeout)
   */
  uint64_t timeout_ms;
} CoreInferenceParams;

/**
 * Inference result (for non-streaming)
 */
typedef struct CoreInferenceResult {
  /**
   * Output tokens (caller must free with core_free_tokens)
   */
  uint32_t *tokens;
  /**
   * Number of output tokens
   */
  uint32_t token_count;
  /**
   * Whether generation finished normally
   */
  bool finished;
} CoreInferenceResult;

/**
 * Model metadata
 */
typedef struct CoreModelMetadata {
  /**
   * Model name (borrowed, valid until model unloaded)
   */
  const char *name;
  /**
   * Model size in bytes
   */
  uint64_t size_bytes;
  /**
   * Model handle ID
   */
  uint64_t handle_id;
} CoreModelMetadata;

/**
 * Runtime configuration (C-compatible struct)
 */
typedef struct CoreConfig {
  /**
   * Base path for models directory (NULL = current directory)
   */
  const char *base_path;
  /**
   * Authentication token (required, non-NULL)
   */
  const char *auth_token;
  /**
   * Session timeout in seconds (default: 3600)
   */
  uint64_t session_timeout_secs;
  /**
   * Maximum context length (default: 4096)
   */
  uint32_t max_context_length;
  /**
   * Maximum queue depth (default: 1000)
   */
  uint32_t max_queue_depth;
  /**
   * Shutdown timeout in seconds (default: 30)
   */
  uint64_t shutdown_timeout_secs;
} CoreConfig;

/**
 * Streaming callback signature
 * Return false to cancel streaming
 */
typedef bool (*CoreStreamCallback)(void *user_data, uint32_t token, bool is_final, const char *error);





/**
 * Authenticate with token, returns session handle
 */
CoreErrorCode core_authenticate(struct CoreRuntime *runtime,
                                const char *token,
                                struct CoreSession **out_session);

/**
 * Validate existing session
 */
CoreErrorCode core_session_validate(struct CoreRuntime *runtime, struct CoreSession *session);

/**
 * Release session handle
 */
void core_session_release(struct CoreSession *session);

/**
 * Get session ID string (borrowed pointer, valid until session released)
 */
const char *core_session_id(const struct CoreSession *session);

/**
 * Get the last error message (C API)
 */
const char *core_get_last_error(void);

/**
 * Clear the last error message (C API)
 */
void core_clear_last_error(void);

/**
 * Health check (no authentication required)
 */
CoreErrorCode core_health_check(struct CoreRuntime *runtime, struct CoreHealthReport *out_report);

/**
 * Liveness check (simple boolean)
 */
bool core_is_alive(struct CoreRuntime *runtime);

/**
 * Readiness check (simple boolean)
 */
bool core_is_ready(struct CoreRuntime *runtime);

/**
 * Get metrics as JSON string (caller must free with core_free_string)
 */
CoreErrorCode core_get_metrics_json(struct CoreRuntime *runtime, char **out_json);

/**
 * Submit inference request (blocking)
 */
CoreErrorCode core_infer(struct CoreRuntime *runtime,
                         struct CoreSession *session,
                         const char *model_id,
                         const uint32_t *prompt_tokens,
                         uint32_t prompt_token_count,
                         const struct CoreInferenceParams *params,
                         struct CoreInferenceResult *out_result);

/**
 * Submit inference request with timeout (blocking)
 */
CoreErrorCode core_infer_with_timeout(struct CoreRuntime *runtime,
                                      struct CoreSession *session,
                                      const char *model_id,
                                      const uint32_t *prompt_tokens,
                                      uint32_t prompt_token_count,
                                      const struct CoreInferenceParams *params,
                                      uint64_t timeout_ms,
                                      struct CoreInferenceResult *out_result);

/**
 * Free tokens from inference result
 */
void core_free_tokens(uint32_t *tokens, uint32_t count);

/**
 * Load a model from path (relative to base_path/models/)
 */
CoreErrorCode core_model_load(struct CoreRuntime *runtime,
                              const char *model_path,
                              uint64_t *out_handle_id);

/**
 * Unload a model by handle
 */
CoreErrorCode core_model_unload(struct CoreRuntime *runtime, uint64_t handle_id);

/**
 * Get model info
 */
CoreErrorCode core_model_info(struct CoreRuntime *runtime,
                              uint64_t handle_id,
                              struct CoreModelMetadata *out_metadata);

/**
 * Free model metadata
 */
void core_free_model_metadata(struct CoreModelMetadata *metadata);

/**
 * List all loaded models
 */
CoreErrorCode core_model_list(struct CoreRuntime *runtime,
                              uint64_t *out_handles,
                              uint32_t max_count,
                              uint32_t *out_count);

/**
 * Get count of loaded models
 */
CoreErrorCode core_model_count(struct CoreRuntime *runtime, uint32_t *out_count);

/**
 * Get default configuration values
 */
void core_config_default(struct CoreConfig *config);

/**
 * Create runtime with configuration
 */
CoreErrorCode core_runtime_create(const struct CoreConfig *config,
                                  struct CoreRuntime **out_runtime);

/**
 * Destroy runtime (blocks until graceful shutdown)
 */
void core_runtime_destroy(struct CoreRuntime *runtime);

/**
 * Submit streaming inference request (blocks until complete/cancelled)
 */
CoreErrorCode core_infer_streaming(struct CoreRuntime *runtime,
                                   struct CoreSession *session,
                                   const char *model_id,
                                   const uint32_t *prompt_tokens,
                                   uint32_t prompt_token_count,
                                   const struct CoreInferenceParams *params,
                                   CoreStreamCallback callback,
                                   void *user_data);

/**
 * Free string allocated by core functions
 */
void core_free_string(char *s);

#ifdef __cplusplus
}
#endif

#endif /* VERITAS_SPARK_H */
